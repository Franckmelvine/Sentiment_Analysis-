name: Evaluate Model

on:
  workflow_run:
    workflows: ["Run Tests and Lint"]
    types:
      - completed   

jobs:
  evaluate:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install torch transformers datasets scikit-learn

      - name: Run evaluation script
        run: python src/evaluate.py  # ✅ Corrigé ici

      - name: Upload metrics
        uses: actions/upload-artifact@main
        with:
          name: model-metrics
          path: metrics.json

      - name: Générer un mini-rapport
        run: python src/performance_report.py
        

      - name: Check accuracy threshold
        run: |
          ACCURACY=$(python -c "import json; d=json.load(open('metrics.json')); print(d['accuracy'])")
          echo "Model accuracy: $ACCURACY"
          if (( $(echo "$ACCURACY < 0.9" | bc -l) )); then
            echo "❌ Model accuracy is below threshold (0.9)"
            exit 1
          else
            echo "✅ Model accuracy is acceptable"
          fi
