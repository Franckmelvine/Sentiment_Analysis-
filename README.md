# ğŸ’¬ Sentiment Analysis Pipeline â€“ MLOps Edition

[![Tests](https://github.com/OwenDiel/sentiment-analysis-pipeline/actions/workflows/test.yml/badge.svg)]
[![Build](https://github.com/OwenDiel/sentiment-analysis-pipeline/actions/workflows/build.yml/badge.svg)]
[![Evaluate](https://github.com/OwenDiel/sentiment-analysis-pipeline/actions/workflows/evaluate.yml/badge.svg)]

## ğŸš€ Objectif

Ce projet implÃ©mente une solution complÃ¨te de dÃ©tection de sentiments avec un modÃ¨le BERT, intÃ©grÃ©e dans un pipeline MLOps avec Docker, GitHub Actions, FastAPI et Streamlit.

---

## ğŸ§± StructureÂ duÂ Projet

Sentiment-Analysis-Pipeline/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ test.yml
â”‚       â”œâ”€â”€ evaluate.yml
â”‚       â”œâ”€â”€ build.yml
â”‚       â””â”€â”€ release.yml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ _init_.py
â”‚   â”œâ”€â”€ data_extraction.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ app.py  # Fichier de dÃ©ploiement
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ _init_.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.csv
â”‚   â””â”€â”€ test.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€Â .gitignore


---

## âš™ï¸ Installation locale

git clone https://github.com/Franckmelvine/Sentiment_Analysis-.git
cd Sentiment_Analysis-
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate sous Windows
pip install -r requirements.txt 

## ğŸ³ Utilisation avec Docker
### Lancer l'API avec Docker Compose

docker compose up --build

Puis accÃ©der Ã  la documentation interactive :
ğŸ“ http://localhost:8000/docs

## ğŸ§ª Exemple dâ€™appel API

POST /predict
Content-Type: application/json

{
  "text": "This is the best app ever!"
}

### ğŸ“¤ RÃ©ponse attendue :

{
  "sentiment": "positive"
}

## ğŸ§¬ Ã‰valuation du modÃ¨le
L'Ã©valuation est automatisÃ©e via GitHub Actions (evaluate.yml) aprÃ¨s chaque test.
Elle gÃ©nÃ¨re un fichier metrics.json contenant la prÃ©cision.

## ğŸ§° DÃ©ploiement Streamlit
Vous pouvez Ã©galement utiliser lâ€™interface utilisateur via :
streamlit run app.py

Cela ouvre une interface web locale pour soumettre du texte et obtenir des prÃ©dictions de sentiment.

## ğŸ› ï¸ Workflows GitHub Actions

âœ… test.yml : exÃ©cute les tests unitaires et vÃ©rifie le lint

âœ… evaluate.yml : Ã©value le modÃ¨le et stocke les mÃ©triques

âœ… build.yml : build Docker sur main

âœ… release.yml : crÃ©ation automatique de release via GitHub tags

## ğŸ‘¥ Auteurs & RÃ©partition
Ã‰tudiant	TÃ¢ches principales
Melvine	Docker, FastAPI, Streamlit, README, Rapport
Owen	GitHub Actions, tests, Ã©valuation, lint

## ğŸ“„ Rapport
Le rapport rapport_MLOps.pdf fournit :

Lâ€™architecture technique

Les choix faits

La rÃ©partition des tÃ¢ches

Les problÃ¨mes rencontrÃ©s et rÃ©solus

Des idÃ©es dâ€™amÃ©lioration future

## ğŸ”® AmÃ©liorations possibles
IntÃ©gration de MLflow pour le suivi dâ€™expÃ©riences

Ajout de tests dâ€™intÃ©gration API

Monitoring avec Prometheus + Grafana

DÃ©ploiement via AWS / GCP

## ğŸ Merci !

